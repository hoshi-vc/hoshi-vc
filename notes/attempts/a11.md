This document is currently only available in Japanese.
Please [use machine translation](https://github-com.translate.goog/hoshi-vc/hoshi-vc?_x_tr_sl=ja&_x_tr_tl=en&_x_tr_hl=en&_x_tr_pto=wapp) if necessary.

# a11 : 様々なアイデアの検証

## a11

```
試行: 単純化してみる
経緯: 全部入りのモデルは煩雑で扱いたくないのです
評価方法: それなりの速さで実行できて、それなりの spksim が出て、恒等変換の音声が十分聞き取れればいいです！
結果: 大丈夫そうです！
```

## a11a

```
試行: ref sampling に使うキーを適宜更新してみる
経緯:
  今までは hubert-soft の近いフレームほど参照したくなるだろうと予想して ref sampling を行っていた。
  しかし attention map を見たところ、モデルはバラバラなフレームを参照しているようだった。
  言い換えると、連続したフレームを活用する様子は部分的にしか見られなかった。
  hubert-soft と key に要求される情報の性質が異なることが原因ではないかと予想した。（例えば key はピッチを軽視して良い）
  このミスマッチのため、音声の切り貼りより、単なる再合成に近い処理をモデルが学習しているのではないかと考えた。
  この試行の結果として、より変換に適した key を作成可能となり、モデルがより長いフレームを参照するようになることを期待している。
評価方法:
  より長く連続したフラグメントを参照するようになったら予想通りです！
結果:
  何も変化が見られないです！
```

## a11aa

```
試行: ref sampling に使うキーを a11a の学習結果からはじめてみる
経緯:
  試行 a11a では、見たところ何も変化しなかった。
  もしかしたら学習初期の挙動に変化があるかもしれないと考え、初めから hubert-soft でないキーを使うことにした
評価方法:
  学習初期の挙動が a11 と違っていたなら予想通りです！
結果:
  何も変化が見られないです！
```
